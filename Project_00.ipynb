{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxAi+QcyLj/jXCfiqPpC2f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmnaAkram987/AmnaAkram987/blob/main/Project_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxR0QvhfWmvm"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_google_genai\n",
        "%pip install -U tavily-python langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langgraph-checkpoint-postgres psycopg psycopg-pool langchain_google_genai"
      ],
      "metadata": {
        "id": "Uhfx6iQURxbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "eayAW6SLX90_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\"\n",
        "\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "id": "WDORzEMyXWrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from  langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model= \"gemini-1.5-flash\",\n",
        "    max_tries=3,\n",
        "    api_key=gemini_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "zkCLt-YhYKoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"hi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "Hrs5BcMZaKhY",
        "outputId": "4c969d9b-080b-461d-8004-8b785000aac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ChatGoogleGenerativeAIError",
          "evalue": "Invalid argument provided to Gemini: 400 API key expired. Please renew the API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key expired. Please renew the API key.\"\n]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    831\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgument\u001b[0m: 400 API key expired. Please renew the API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key expired. Please renew the API key.\"\n]",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mChatGoogleGenerativeAIError\u001b[0m               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f2e6715bd619>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         return cast(\n\u001b[1;32m    285\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    785\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         flattened_outputs = [\n\u001b[1;32m    645\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 results.append(\n\u001b[0;32m--> 633\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    634\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    852\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0mtool_choice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_choice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         )\n\u001b[0;32m--> 949\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m    950\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post_retry_check_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"RetryCallState\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_run_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgument\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             raise ChatGoogleGenerativeAIError(\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0;34mf\"Invalid argument provided to Gemini: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             ) from e\n",
            "\u001b[0;31mChatGoogleGenerativeAIError\u001b[0m: Invalid argument provided to Gemini: 400 API key expired. Please renew the API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key expired. Please renew the API key.\"\n]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chatbot Specifications and Features**:\n",
        "\n",
        "- Powered by Gemini-1.5-Flash for advanced language understanding.  \n",
        "- Uses `TypedDict` and reducer for dynamic state management.  \n",
        "- Integrates TavilySearchResults for real-time web search.  \n",
        "- Includes MemorySaver for maintaining thread context.  \n",
        "- Focused on CS subjects (OOPS, DBMS, Networking, etc.) with resource recommendations (MDN, W3Schools, LeetCode).  \n",
        "- Built with `StateGraph` for modular, scalable design.  "
      ],
      "metadata": {
        "id": "zynN2CZxXIIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "DB_URI = userdata.get('DB_URL')"
      ],
      "metadata": {
        "id": "eDOo1lYFfZ-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psycopg_pool import ConnectionPool\n",
        "from langgraph.checkpoint.postgres import PostgresSaver\n",
        "\n",
        "# Connection pool for efficient database access\n",
        "connection_kwargs = {\"autocommit\": True, \"prepare_threshold\": 0}\n",
        "\n",
        "# Create a persistent connection pool\n",
        "pool = ConnectionPool(conninfo=DB_URI, max_size=20, kwargs=connection_kwargs)\n",
        "\n",
        "# Initialize PostgresSaver checkpointer\n",
        "checkpointer = PostgresSaver(pool)\n",
        "checkpointer.setup()  # Ensure database tables are set up"
      ],
      "metadata": {
        "id": "_83nsbxRfbl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import START , END , StateGraph\n",
        "from langgraph.graph.message  import add_messages\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langgraph.prebuilt import ToolNode ,tools_condition\n",
        "from  langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "#reducer\n",
        "class State(TypedDict):\n",
        "  messages:Annotated[list[BaseMessage],add_messages]\n"
      ],
      "metadata": {
        "id": "qRxHGaU5fy-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# llm\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model= \"gemini-1.5-flash\",\n",
        "    max_retries=3,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "\n",
        "#Tavily web search tool\n",
        "tool=TavilySearchResults(max_results=3)\n",
        "tools=[tool]\n",
        "\n",
        "llm_with_tool = llm.bind_tools(tools)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"This chatbot assists students in learning core CS subjects like OOPS, DBMS, Programming, \"\n",
        "                   \"Networking, DSA, ICT, and AI. It provides clear explnation and  suggests resources  and focuses on both theory and practice.\"\n",
        "                    \"Also call a tool when needed  for web search for real world query or resources It will only answer CS-related queries.\"\n",
        "                    \" Search the web for the latest resources, tools, and trends when relevant.\"),\n",
        "        (\"placeholder\", \"{messages}\"),\n",
        "        (\"user\", \"Remember, You are an expert engineer and mentor who help students to build strong foundation.\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "def chatbot(state:State):\n",
        "  #modified_prompt = prompt.format( messages = state[\"messages\"])\n",
        "  #return {\"messages\":[llm_with_tool.invoke(modified_prompt)]}\n",
        "  return {\"messages\": [llm_with_tool.invoke(state[\"messages\"])]}\n",
        "\n",
        "#Introducing memory in while  thread is same\n",
        "memory = MemorySaver()\n",
        "\n",
        "#config\n",
        "config={\"configurable\" :{\"thread_id\": \"1\" } }\n",
        "\n",
        "\n",
        "# Build Graph\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\",chatbot) #added node1\n",
        "\n",
        "tool_node=ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\",tool_node) #added node2\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\" , tools_condition ,\n",
        ")\n",
        "\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "\n",
        "graph = graph_builder.compile(checkpointer=memory ,  interrupt_before=[\"tools\"],)\n",
        "\n",
        "\n",
        "#Compile graph\n",
        "#graph = graph_builder.compile(checkpointer= memory)\n",
        "\n",
        "user_input = \"Search for latest AI news\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqyozwV3cJjg",
        "outputId": "64349732-1f97-4a8a-fc02-242ea855282a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Search for latest AI news\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (31433984-1822-4d7f-b4c9-7d2a8f6b84c2)\n",
            " Call ID: 31433984-1822-4d7f-b4c9-7d2a8f6b84c2\n",
            "  Args:\n",
            "    query: latest AI news\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "R13qBKqPEqFX",
        "outputId": "28c29459-9156-4194-d158-e69666ba9fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"Search for the top coding practices for competitive programming.\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V_w8GJ49SF1",
        "outputId": "e51a1e3d-69ae-48c0-eca3-49bcaf6519b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Search for the top coding practices for competitive programming.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (ff76fbd6-bfca-498d-8932-cc06e2c1853f)\n",
            " Call ID: ff76fbd6-bfca-498d-8932-cc06e2c1853f\n",
            "  Args:\n",
            "    query: top coding practices for competitive programming\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.next"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wXt6ETWQUXO",
        "outputId": "7a930470-eb6b-4b6b-b547-9c78894f23bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tools',)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "\n",
        "# Run the graph until the first interruption\n",
        "for event in graph.stream(user_input, thread, stream_mode=\"values\"):\n",
        "    event['messages'][-1].pretty_print()\n",
        "\n",
        "# Get user feedback\n",
        "user_approval = input(\"Do you want to call the tool? (yes/no): \")\n",
        "\n",
        "# Check approval\n",
        "if user_approval.lower() == \"yes\":\n",
        "\n",
        "    # If approved, continue the graph execution\n",
        "    for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
        "        event['messages'][-1].pretty_print()\n",
        "\n",
        "else:\n",
        "    print(\"Operation cancelled by user.\")"
      ],
      "metadata": {
        "id": "AzuwPrDVlcEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
        "events = graph.stream(None, config, stream_mode=\"values\")\n",
        "for event in events:\n",
        "    if \"messages\" in event:\n",
        "        event[\"messages\"][-1].pretty_print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLbJUfLpQfn5",
        "outputId": "118ce57c-908a-4da6-8963-02b2395c44bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search_results_json (ff76fbd6-bfca-498d-8932-cc06e2c1853f)\n",
            " Call ID: ff76fbd6-bfca-498d-8932-cc06e2c1853f\n",
            "  Args:\n",
            "    query: top coding practices for competitive programming\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"url\": \"https://www.quora.com/What-is-the-best-strategy-to-improve-my-skills-in-competitive-programming-in-C++-in-2-3-months\", \"content\": \"So yes, the best strategy to improve your competitive programming skill is to practice a lot, but you must solve gradually harder problems, not just the easy ones. Structured preparation for problem-solving (DSA) is crucial, rather than practicing problems randomly on platforms like LeetCode or GeeksforGeeks . o First 4 Months: Focus on coding interviews by teaching DSA, problem-solving techniques, and practicing company-specific questions. Devoting a few hours everyday to just grinding through problems can be very helpful and can really improve your competitive programming skill. If youre preparing for job interviews, practice with mock interviews that focus on problem-solving under time constraints. What is the best problem solving strategy for a team of 3 in competitive programming?\"}, {\"url\": \"https://www.reddit.com/r/csMajors/comments/z4qjzx/a_guide_to_competitive_programming/\", \"content\": \"Note that you can also use Codeforces in a similar way, but I particularly like that AtCoder has very easy problems to allow people with no experience to dive straight into competitive programming. The reason I wanted to mention it is that it's a superb resource if you are interested in algorithms/problem solving/math in general, and I can say with confidence that even if I hadn't persisted with competitive programming, it'd still be worth every penny. As you solve problems, make sure to look at the top competitors' code/editorial code, as doing so will gradually expose you to the C++ features required for competitive programming.\"}, {\"url\": \"https://medium.com/codess-cafe/the-ultimate-guide-to-competitive-programming-7bde37b70f45\", \"content\": \"Mar 21, 2022 ... Writing accurate and fast code is a huge part of CP and this can only be improved by getting into a live contest. Also, get yourself around\"}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Top coding practices for competitive programming include consistent practice on platforms like LeetCode or Codeforces, focusing on progressively harder problems rather than just easy ones.  Structured preparation in data structures and algorithms (DSA) is crucial.  Reviewing top competitor's code and editorials helps expose you to efficient coding techniques and C++ features commonly used in competitive programming.  Participating in live contests improves speed and accuracy under pressure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"Summarize the conversation till now\"\n",
        "\n",
        "# The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
        ")\n",
        "for event in events:\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT3OEih5Oi_I",
        "outputId": "6bba6461-eb29-4d78-a35f-cd64d576e40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Summarize the conversation till now\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Our conversation began with you asking me to search for the latest AI news using the available `default_api`.  Then, you asked me to search for top coding practices for competitive programming, again using the same API.  I provided summaries of the search results in both cases. Finally, you asked me to summarize the conversation, which I am doing now.\n"
          ]
        }
      ]
    }
  ]
}